<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>2025-1-22</title>
    <link href="/2025/02/19/2025-1-22/"/>
    <url>/2025/02/19/2025-1-22/</url>
    
    <content type="html"><![CDATA[<h1 id="Evaluating-Retrieval-Quality-in-Retrieval-Augmented-Generation"><a href="#Evaluating-Retrieval-Quality-in-Retrieval-Augmented-Generation" class="headerlink" title="Evaluating Retrieval Quality in Retrieval-Augmented Generation"></a><a href="https://dl.acm.org/doi/abs/10.1145/3626772.3657957">Evaluating Retrieval Quality in Retrieval-Augmented Generation</a></h1><h2 id="本文介绍了一种评估RAG检索模型表现的方法eRAG，传统的end-to-end方法缺乏可解释性且需要较大资源，eRAG能节约50倍的显存并且与模型性能相关性更高（即该评估方法更好）。"><a href="#本文介绍了一种评估RAG检索模型表现的方法eRAG，传统的end-to-end方法缺乏可解释性且需要较大资源，eRAG能节约50倍的显存并且与模型性能相关性更高（即该评估方法更好）。" class="headerlink" title="本文介绍了一种评估RAG检索模型表现的方法eRAG，传统的end-to-end方法缺乏可解释性且需要较大资源，eRAG能节约50倍的显存并且与模型性能相关性更高（即该评估方法更好）。"></a>本文介绍了一种评估RAG检索模型表现的方法eRAG，传统的end-to-end方法缺乏可解释性且需要较大资源，eRAG能节约50倍的显存并且与模型性能相关性更高（即该评估方法更好）。</h2><h2 id="eRAG"><a href="#eRAG" class="headerlink" title="eRAG:"></a>eRAG:</h2><ol><li>文档单独评估：对于检索模型返回的每个文档，将其单独输入到LLM中，并生成对应的输出。</li><li>生成相关性标签：利用下游任务的评价函数对LLM的输出进行评估，生成每个文档的相关性标签。</li><li>聚合评估结果：使用集合或排名指标对文档级别的相关性标签进行聚合，得到检索结果的整体评估分数。</li></ol><h2 id="节约显存："><a href="#节约显存：" class="headerlink" title="节约显存："></a>节约显存：</h2><h3 id="Vanilla-Transformer-O-n-2"><a href="#Vanilla-Transformer-O-n-2" class="headerlink" title="Vanilla Transformer -&gt; $O({n^2})$"></a>Vanilla Transformer -&gt; $O({n^2})$</h3><h3 id="k-documents"><a href="#k-documents" class="headerlink" title="k -&gt; documents"></a>k -&gt; documents</h3><h3 id="d-average-length-of-documents"><a href="#d-average-length-of-documents" class="headerlink" title="d -&gt; average length of documents"></a>d -&gt; average length of documents</h3><h3 id="l-length-of-output"><a href="#l-length-of-output" class="headerlink" title="l -&gt; length of output"></a>l -&gt; length of output</h3><h3 id="end-to-end-O-lk-2d-2"><a href="#end-to-end-O-lk-2d-2" class="headerlink" title="end-to-end -&gt; $O(lk^2d^2)$"></a>end-to-end -&gt; $O(lk^2d^2)$</h3><h3 id="eRAG-O-lkd-2"><a href="#eRAG-O-lkd-2" class="headerlink" title="eRAG -&gt; $O(lkd^2)$"></a>eRAG -&gt; $O(lkd^2)$</h3><h3 id="优化方法：将每个document独立输入给LLM（k次）"><a href="#优化方法：将每个document独立输入给LLM（k次）" class="headerlink" title="优化方法：将每个document独立输入给LLM（k次）"></a>优化方法：将每个document独立输入给LLM（k次）</h3>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>2025-1-17</title>
    <link href="/2025/02/19/2025-1-17/"/>
    <url>/2025/02/19/2025-1-17/</url>
    
    <content type="html"><![CDATA[<h1 id="Fake-news-disinformation-and-misinformation-in-social-media-a-review"><a href="#Fake-news-disinformation-and-misinformation-in-social-media-a-review" class="headerlink" title="Fake news, disinformation and misinformation in social media: a review"></a><a href="https://link.springer.com/article/10.1007/s13278-023-01028-5">Fake news, disinformation and misinformation in social media: a review</a></h1><h2 id="了解了review的大体结构：总体上，先引入问题，再介绍各种定义（e-g-何为Fake-news）及研究方法（e-g-论文来源-论文筛选原则），再介绍解决方案，最后进行总结；在解决方案部分，先列举各种方向，对引用的论文中的实现方法的说明较为简短。"><a href="#了解了review的大体结构：总体上，先引入问题，再介绍各种定义（e-g-何为Fake-news）及研究方法（e-g-论文来源-论文筛选原则），再介绍解决方案，最后进行总结；在解决方案部分，先列举各种方向，对引用的论文中的实现方法的说明较为简短。" class="headerlink" title="了解了review的大体结构：总体上，先引入问题，再介绍各种定义（e.g.何为Fake news）及研究方法（e.g. 论文来源 论文筛选原则），再介绍解决方案，最后进行总结；在解决方案部分，先列举各种方向，对引用的论文中的实现方法的说明较为简短。"></a>了解了review的大体结构：总体上，先引入问题，再介绍各种定义（e.g.何为Fake news）及研究方法（e.g. 论文来源 论文筛选原则），再介绍解决方案，最后进行总结；在解决方案部分，先列举各种方向，对引用的论文中的实现方法的说明较为简短。</h2><h3 id="Fake-news检测方法分类："><a href="#Fake-news检测方法分类：" class="headerlink" title="Fake news检测方法分类："></a>Fake news检测方法分类：</h3><ol><li>基于新闻内容</li><li>基于社会情境（假新闻本身之外的数据）</li><li>结合上述方法</li></ol><h3 id="Fake-news检测方法（AI相关）："><a href="#Fake-news检测方法（AI相关）：" class="headerlink" title="Fake news检测方法（AI相关）："></a>Fake news检测方法（AI相关）：</h3><ol><li>DL</li><li>ML</li><li>NLP</li></ol></br><h1 id="A-Survey-on-Automated-Fact-Checking"><a href="#A-Survey-on-Automated-Fact-Checking" class="headerlink" title="A Survey on Automated Fact-Checking"></a><a href="https://aclanthology.org/2022.tacl-1.11/">A Survey on Automated Fact-Checking</a></h1><h2 id="这篇综述的结构为引入问题-引入各种定义-解决方案-总结"><a href="#这篇综述的结构为引入问题-引入各种定义-解决方案-总结" class="headerlink" title="这篇综述的结构为引入问题-&gt;引入各种定义-&gt;解决方案-&gt;总结"></a>这篇综述的结构为引入问题-&gt;引入各种定义-&gt;解决方案-&gt;总结</h2><h3 id="事实核查任务定义："><a href="#事实核查任务定义：" class="headerlink" title="事实核查任务定义："></a>事实核查任务定义：</h3><ol><li>Claim Detection（判断声明）</li><li>Evidence Retrieval（检索证据）</li><li>Verdict Prediction（判断）</li><li>Justification Production（证明）</li></ol><h3 id="Claim-Detection：分类任务，将声明分为是否可检查或是否值得检查"><a href="#Claim-Detection：分类任务，将声明分为是否可检查或是否值得检查" class="headerlink" title="Claim Detection：分类任务，将声明分为是否可检查或是否值得检查"></a>Claim Detection：分类任务，将声明分为是否可检查或是否值得检查</h3><h3 id="Evidence-Retrieval-and-Claim-Verification：判断证据是否支持声明"><a href="#Evidence-Retrieval-and-Claim-Verification：判断证据是否支持声明" class="headerlink" title="Evidence Retrieval and Claim Verification：判断证据是否支持声明"></a>Evidence Retrieval and Claim Verification：判断证据是否支持声明</h3><h3 id="Justification-Production：证明过程需要遵循可读性合理性忠实性"><a href="#Justification-Production：证明过程需要遵循可读性合理性忠实性" class="headerlink" title="Justification Production：证明过程需要遵循可读性合理性忠实性"></a>Justification Production：证明过程需要遵循可读性合理性忠实性</h3></br><h1 id="Retrieval-Augmented-Generation-for-Large-Language-Models-A-Survey"><a href="#Retrieval-Augmented-Generation-for-Large-Language-Models-A-Survey" class="headerlink" title="Retrieval-Augmented Generation for Large Language Models: A Survey"></a><a href="https://arxiv.org/abs/2312.10997">Retrieval-Augmented Generation for Large Language Models: A Survey</a></h1><h3 id="RAG分类："><a href="#RAG分类：" class="headerlink" title="RAG分类："></a>RAG分类：</h3><ol><li>Naive RAG</li><li>Advanced RAG（检索前检索后检索中优化）</li><li>Modular RAG（Agent化）</li></ol><h3 id=""><a href="#" class="headerlink" title=""></a><img src="/2025/02/19/2025-1-17/RAG_FrameCompre_eng.png" alt="alt text"></h3><h3 id="检索："><a href="#检索：" class="headerlink" title="检索："></a>检索：</h3><ol><li>检索源（数据结构 数据颗粒度）</li><li>索引优化（分块 元数据 结构化）</li><li>查询优化（扩大查询 转换查询 查询路由）</li><li>嵌入</li></ol><h3 id="生成："><a href="#生成：" class="headerlink" title="生成："></a>生成：</h3><ol><li>上下文管理（重排检索块 上下文选择）</li><li>微调</li></ol><h3 id="增强："><a href="#增强：" class="headerlink" title="增强："></a>增强：</h3><ol><li>迭代检索（反复搜索知识库）</li><li>递归检索（基于先前搜索结果多次改进检索）</li><li>自适应检索（由模型自行决定检索时机与内容）</li></ol><h3 id="评估RAG："><a href="#评估RAG：" class="headerlink" title="评估RAG："></a>评估RAG：</h3><ol><li>检索质量</li><li>生成质量</li></ol><h3 id="前景："><a href="#前景：" class="headerlink" title="前景："></a>前景：</h3><ol><li>长上下文问题</li><li>健壮性（噪音或矛盾信息）</li><li>与微调结合</li><li>Scaling laws of RAG</li><li>提高检索效率</li><li>确保检索数据安全</li><li>多模态RAG（图片音频视频代码）</li></ol><h3 id="-1"><a href="#-1" class="headerlink" title=""></a><img src="/2025/02/19/2025-1-17/rag_summary.png" alt="alt text"></h3>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
